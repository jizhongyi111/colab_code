{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Intro3.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "IJTA-KDFbamt",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# 入门提高\n",
        "\n",
        "*  挂载Google网盘，对CoLAB可见\n",
        "\n",
        "*  上传训练代码压缩包\n",
        "\n",
        "*   解压压缩包\n",
        "\n",
        "*   重新安装PyTorch\n",
        "\n",
        "*   更改当前工作目录\n",
        "\n",
        "*   命令行运行代码"
      ]
    },
    {
      "metadata": {
        "id": "GvrcgV9bXaen",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7ee97b4f-3e35-4bbc-c877-a4445a3a0247"
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "cur_dir = os.getcwd()\n",
        "print(cur_dir)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "6MWHu6JZgJTT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "8cd9c3f4-cdf3-4ab9-d494-f0c8bdb861c0"
      },
      "cell_type": "code",
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mnist  sample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7yhV1v4Zf_Uh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "5c50a507-d47d-42be-d847-5fb05096fe4b"
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=email%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdocs.test%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive.photos.readonly%20https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fpeopleapi.readonly&response_type=code\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "bqXheiXSwgTr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "d97ae442-b22c-4f77-b185-515a06c5d1f5"
      },
      "cell_type": "code",
      "source": [
        "cur_dir = os.getcwd()\n",
        "print(cur_dir)"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "2MbDyLz-wwWt",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "with zipfile.ZipFile(\"/content/gdrive/My Drive/CNN_Denoising_Demo.zip\",\"r\") as zip_ref:\n",
        "    zip_ref.extractall(\"/content/gdrive/My Drive/\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V7b2l--c1YD9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Oyx-O45JpY22",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 97
        },
        "outputId": "1da18471-d6db-4759-cad6-e400a3ae65ae"
      },
      "cell_type": "code",
      "source": [
        "# http://pytorch.org/\n",
        "from os.path import exists\n",
        "from wheel.pep425tags import get_abbr_impl, get_impl_ver, get_abi_tag\n",
        "platform = '{}{}-{}'.format(get_abbr_impl(), get_impl_ver(), get_abi_tag())\n",
        "cuda_output = !ldconfig -p|grep cudart.so|sed -e 's/.*\\.\\([0-9]*\\)\\.\\([0-9]*\\)$/cu\\1\\2/'\n",
        "accelerator = cuda_output[0] if exists('/dev/nvidia0') else 'cpu'\n",
        "\n",
        "!pip install -q http://download.pytorch.org/whl/{accelerator}/torch-0.4.1-{platform}-linux_x86_64.whl torchvision\n",
        "import torch"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tcmalloc: large alloc 1073750016 bytes == 0x5758a000 @  0x7f253ef072a4 0x594e17 0x626104 0x51190a 0x4f5277 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x4f3338 0x510fb0 0x5119bd 0x4f6070\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xP75j9tt1o6w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1e6f16f1-2d9d-4ce2-8a21-5b745e499be6"
      },
      "cell_type": "code",
      "source": [
        "cur_dir = os.getcwd()\n",
        "print(cur_dir)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5sf4mX3R3R_R",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.chdir(\"gdrive/My Drive/CNN_Denoising_Demo\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "j4GRoNF03Xhc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "5bb80fcd-1320-4536-f38a-8dda1cadf06c"
      },
      "cell_type": "code",
      "source": [
        "cur_dir = os.getcwd()\n",
        "print(cur_dir)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/CNN_Denoising_Demo\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "GObwKIb0AW2B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 20174
        },
        "outputId": "bf474fec-f252-4e0e-92ba-0840aa2405eb"
      },
      "cell_type": "code",
      "source": [
        "!python CNN_Denoise_Train_Run.py"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "process training data\n",
            "file: data/train/test_001.png scale 1.0 # samples: 225\n",
            "file: data/train/test_001.png scale 0.9 # samples: 169\n",
            "file: data/train/test_001.png scale 0.8 # samples: 121\n",
            "file: data/train/test_001.png scale 0.7 # samples: 81\n",
            "file: data/train/test_002.png scale 1.0 # samples: 225\n",
            "file: data/train/test_002.png scale 0.9 # samples: 169\n",
            "file: data/train/test_002.png scale 0.8 # samples: 121\n",
            "file: data/train/test_002.png scale 0.7 # samples: 81\n",
            "file: data/train/test_003.png scale 1.0 # samples: 225\n",
            "file: data/train/test_003.png scale 0.9 # samples: 169\n",
            "file: data/train/test_003.png scale 0.8 # samples: 121\n",
            "file: data/train/test_003.png scale 0.7 # samples: 81\n",
            "file: data/train/test_004.png scale 1.0 # samples: 225\n",
            "file: data/train/test_004.png scale 0.9 # samples: 169\n",
            "file: data/train/test_004.png scale 0.8 # samples: 121\n",
            "file: data/train/test_004.png scale 0.7 # samples: 81\n",
            "file: data/train/test_005.png scale 1.0 # samples: 225\n",
            "file: data/train/test_005.png scale 0.9 # samples: 169\n",
            "file: data/train/test_005.png scale 0.8 # samples: 121\n",
            "file: data/train/test_005.png scale 0.7 # samples: 81\n",
            "file: data/train/test_006.png scale 1.0 # samples: 225\n",
            "file: data/train/test_006.png scale 0.9 # samples: 169\n",
            "file: data/train/test_006.png scale 0.8 # samples: 121\n",
            "file: data/train/test_006.png scale 0.7 # samples: 81\n",
            "file: data/train/test_397.png scale 1.0 # samples: 225\n",
            "file: data/train/test_397.png scale 0.9 # samples: 169\n",
            "file: data/train/test_397.png scale 0.8 # samples: 121\n",
            "file: data/train/test_397.png scale 0.7 # samples: 81\n",
            "\n",
            "process validation data\n",
            "file: data/Set12/01.png\n",
            "file: data/Set12/02.png\n",
            "file: data/Set12/03.png\n",
            "file: data/Set12/04.png\n",
            "file: data/Set12/05.png\n",
            "file: data/Set12/06.png\n",
            "file: data/Set12/07.png\n",
            "file: data/Set12/08.png\n",
            "file: data/Set12/09.png\n",
            "file: data/Set12/10.png\n",
            "file: data/Set12/11.png\n",
            "file: data/Set12/12.png\n",
            "training set, # samples 4172\n",
            "\n",
            "val set, # samples 12\n",
            "\n",
            "Loading dataset ...\n",
            "\n",
            "# of training samples: 4172\n",
            "\n",
            "/content/gdrive/My Drive/CNN_Denoising_Demo/utils.py:10: UserWarning: nn.init.kaiming_normal is now deprecated in favor of nn.init.kaiming_normal_.\n",
            "  nn.init.kaiming_normal(m.weight.data, a=0, mode='fan_in')\n",
            "/content/gdrive/My Drive/CNN_Denoising_Demo/utils.py:16: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n",
            "  nn.init.constant(m.bias.data, 0.0)\n",
            "/usr/local/lib/python3.6/dist-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
            "  warnings.warn(warning.format(ret))\n",
            "learning rate 0.000100\n",
            "[epoch 1][1/66] loss: 180.9056 PSNR_train: 7.2423\n",
            "[epoch 1][2/66] loss: 165.1305 PSNR_train: 7.4542\n",
            "[epoch 1][3/66] loss: 157.6571 PSNR_train: 7.6654\n",
            "[epoch 1][4/66] loss: 159.0495 PSNR_train: 7.8556\n",
            "[epoch 1][5/66] loss: 143.6249 PSNR_train: 8.2601\n",
            "[epoch 1][6/66] loss: 172.2482 PSNR_train: 7.2447\n",
            "[epoch 1][7/66] loss: 142.8832 PSNR_train: 7.9481\n",
            "[epoch 1][8/66] loss: 151.4905 PSNR_train: 7.8138\n",
            "[epoch 1][9/66] loss: 124.2913 PSNR_train: 8.8763\n",
            "[epoch 1][10/66] loss: 156.6948 PSNR_train: 7.7586\n",
            "[epoch 1][11/66] loss: 162.4715 PSNR_train: 7.1251\n",
            "[epoch 1][12/66] loss: 162.8683 PSNR_train: 7.3889\n",
            "[epoch 1][13/66] loss: 156.5126 PSNR_train: 7.4485\n",
            "[epoch 1][14/66] loss: 142.6989 PSNR_train: 7.9696\n",
            "[epoch 1][15/66] loss: 139.5718 PSNR_train: 7.9738\n",
            "[epoch 1][16/66] loss: 124.0955 PSNR_train: 8.3450\n",
            "[epoch 1][17/66] loss: 123.2033 PSNR_train: 8.4571\n",
            "[epoch 1][18/66] loss: 137.1743 PSNR_train: 7.6008\n",
            "[epoch 1][19/66] loss: 134.7031 PSNR_train: 8.0359\n",
            "[epoch 1][20/66] loss: 154.1727 PSNR_train: 7.0212\n",
            "[epoch 1][21/66] loss: 151.9602 PSNR_train: 7.1096\n",
            "[epoch 1][22/66] loss: 130.3322 PSNR_train: 7.7865\n",
            "[epoch 1][23/66] loss: 119.1221 PSNR_train: 8.2679\n",
            "[epoch 1][24/66] loss: 118.9837 PSNR_train: 8.2121\n",
            "[epoch 1][25/66] loss: 133.0918 PSNR_train: 7.6386\n",
            "[epoch 1][26/66] loss: 127.0331 PSNR_train: 8.0579\n",
            "[epoch 1][27/66] loss: 122.8982 PSNR_train: 8.0800\n",
            "[epoch 1][28/66] loss: 119.7937 PSNR_train: 8.0181\n",
            "[epoch 1][29/66] loss: 126.9780 PSNR_train: 7.6301\n",
            "[epoch 1][30/66] loss: 129.9854 PSNR_train: 7.5099\n",
            "[epoch 1][31/66] loss: 125.0489 PSNR_train: 7.8113\n",
            "[epoch 1][32/66] loss: 112.8287 PSNR_train: 8.4278\n",
            "[epoch 1][33/66] loss: 105.5770 PSNR_train: 8.4291\n",
            "[epoch 1][34/66] loss: 110.5356 PSNR_train: 8.1330\n",
            "[epoch 1][35/66] loss: 120.8115 PSNR_train: 7.4892\n",
            "[epoch 1][36/66] loss: 107.9115 PSNR_train: 8.0194\n",
            "[epoch 1][37/66] loss: 112.3298 PSNR_train: 8.0448\n",
            "[epoch 1][38/66] loss: 105.3309 PSNR_train: 8.5826\n",
            "[epoch 1][39/66] loss: 109.5104 PSNR_train: 7.8233\n",
            "[epoch 1][40/66] loss: 110.0388 PSNR_train: 7.8018\n",
            "[epoch 1][41/66] loss: 105.8852 PSNR_train: 8.2217\n",
            "[epoch 1][42/66] loss: 97.5678 PSNR_train: 8.5443\n",
            "[epoch 1][43/66] loss: 106.2388 PSNR_train: 7.8565\n",
            "[epoch 1][44/66] loss: 92.2386 PSNR_train: 8.8528\n",
            "[epoch 1][45/66] loss: 107.6392 PSNR_train: 7.4796\n",
            "[epoch 1][46/66] loss: 95.5655 PSNR_train: 8.2696\n",
            "[epoch 1][47/66] loss: 110.0460 PSNR_train: 7.5479\n",
            "[epoch 1][48/66] loss: 83.7105 PSNR_train: 8.5673\n",
            "[epoch 1][49/66] loss: 87.4777 PSNR_train: 8.6465\n",
            "[epoch 1][50/66] loss: 91.1678 PSNR_train: 8.4393\n",
            "[epoch 1][51/66] loss: 89.6506 PSNR_train: 8.3230\n",
            "[epoch 1][52/66] loss: 92.0918 PSNR_train: 8.2151\n",
            "[epoch 1][53/66] loss: 85.0667 PSNR_train: 8.2853\n",
            "[epoch 1][54/66] loss: 85.0892 PSNR_train: 8.1753\n",
            "[epoch 1][55/66] loss: 109.6098 PSNR_train: 7.4179\n",
            "[epoch 1][56/66] loss: 85.8255 PSNR_train: 7.9765\n",
            "[epoch 1][57/66] loss: 85.1690 PSNR_train: 8.1628\n",
            "[epoch 1][58/66] loss: 103.4092 PSNR_train: 7.4423\n",
            "[epoch 1][59/66] loss: 84.5227 PSNR_train: 8.1967\n",
            "[epoch 1][60/66] loss: 77.8704 PSNR_train: 8.3480\n",
            "[epoch 1][61/66] loss: 89.8489 PSNR_train: 7.7299\n",
            "[epoch 1][62/66] loss: 81.8710 PSNR_train: 8.0108\n",
            "[epoch 1][63/66] loss: 88.8602 PSNR_train: 7.4524\n",
            "[epoch 1][64/66] loss: 82.1585 PSNR_train: 7.8751\n",
            "[epoch 1][65/66] loss: 76.5384 PSNR_train: 7.8835\n",
            "[epoch 1][66/66] loss: 102.9738 PSNR_train: 6.6619\n",
            "\n",
            "[epoch 1] PSNR_val: 5.6216\n",
            "learning rate 0.000100\n",
            "[epoch 2][1/66] loss: 71.9981 PSNR_train: 8.1576\n",
            "[epoch 2][2/66] loss: 62.3275 PSNR_train: 8.6183\n",
            "[epoch 2][3/66] loss: 80.3722 PSNR_train: 7.6470\n",
            "[epoch 2][4/66] loss: 74.4748 PSNR_train: 7.9006\n",
            "[epoch 2][5/66] loss: 60.1770 PSNR_train: 8.7447\n",
            "[epoch 2][6/66] loss: 58.1995 PSNR_train: 8.8350\n",
            "[epoch 2][7/66] loss: 86.7495 PSNR_train: 7.7410\n",
            "[epoch 2][8/66] loss: 68.7360 PSNR_train: 8.5376\n",
            "[epoch 2][9/66] loss: 79.9826 PSNR_train: 8.2613\n",
            "[epoch 2][10/66] loss: 69.2184 PSNR_train: 9.0451\n",
            "[epoch 2][11/66] loss: 68.3847 PSNR_train: 9.0812\n",
            "[epoch 2][12/66] loss: 56.1614 PSNR_train: 9.5374\n",
            "[epoch 2][13/66] loss: 63.9298 PSNR_train: 9.4016\n",
            "[epoch 2][14/66] loss: 64.7360 PSNR_train: 9.5310\n",
            "[epoch 2][15/66] loss: 59.7560 PSNR_train: 10.0256\n",
            "[epoch 2][16/66] loss: 64.4448 PSNR_train: 10.0028\n",
            "[epoch 2][17/66] loss: 75.6959 PSNR_train: 9.5477\n",
            "[epoch 2][18/66] loss: 59.4635 PSNR_train: 10.2427\n",
            "[epoch 2][19/66] loss: 61.2761 PSNR_train: 10.2063\n",
            "[epoch 2][20/66] loss: 75.6852 PSNR_train: 9.8983\n",
            "[epoch 2][21/66] loss: 56.1798 PSNR_train: 10.5497\n",
            "[epoch 2][22/66] loss: 65.1921 PSNR_train: 10.4912\n",
            "[epoch 2][23/66] loss: 67.4089 PSNR_train: 10.3115\n",
            "[epoch 2][24/66] loss: 56.1461 PSNR_train: 11.0112\n",
            "[epoch 2][25/66] loss: 64.7983 PSNR_train: 10.5309\n",
            "[epoch 2][26/66] loss: 59.6842 PSNR_train: 11.0091\n",
            "[epoch 2][27/66] loss: 54.3664 PSNR_train: 11.2117\n",
            "[epoch 2][28/66] loss: 49.8014 PSNR_train: 11.3424\n",
            "[epoch 2][29/66] loss: 46.2562 PSNR_train: 11.6763\n",
            "[epoch 2][30/66] loss: 54.1329 PSNR_train: 11.4214\n",
            "[epoch 2][31/66] loss: 51.1083 PSNR_train: 11.5881\n",
            "[epoch 2][32/66] loss: 51.9134 PSNR_train: 11.7696\n",
            "[epoch 2][33/66] loss: 49.6814 PSNR_train: 11.8618\n",
            "[epoch 2][34/66] loss: 52.6884 PSNR_train: 11.7682\n",
            "[epoch 2][35/66] loss: 42.5407 PSNR_train: 12.1028\n",
            "[epoch 2][36/66] loss: 44.0735 PSNR_train: 12.5769\n",
            "[epoch 2][37/66] loss: 54.2999 PSNR_train: 12.5322\n",
            "[epoch 2][38/66] loss: 51.8905 PSNR_train: 12.4130\n",
            "[epoch 2][39/66] loss: 47.0250 PSNR_train: 12.3932\n",
            "[epoch 2][40/66] loss: 55.3358 PSNR_train: 12.4373\n",
            "[epoch 2][41/66] loss: 47.7900 PSNR_train: 12.3754\n",
            "[epoch 2][42/66] loss: 44.1283 PSNR_train: 12.7691\n",
            "[epoch 2][43/66] loss: 45.0504 PSNR_train: 12.8065\n",
            "[epoch 2][44/66] loss: 40.0691 PSNR_train: 12.8664\n",
            "[epoch 2][45/66] loss: 39.3238 PSNR_train: 13.0404\n",
            "[epoch 2][46/66] loss: 41.5798 PSNR_train: 13.2640\n",
            "[epoch 2][47/66] loss: 42.4629 PSNR_train: 13.2289\n",
            "[epoch 2][48/66] loss: 36.4800 PSNR_train: 13.7015\n",
            "[epoch 2][49/66] loss: 44.8732 PSNR_train: 13.3987\n",
            "[epoch 2][50/66] loss: 36.6940 PSNR_train: 13.7094\n",
            "[epoch 2][51/66] loss: 30.8421 PSNR_train: 13.5969\n",
            "[epoch 2][52/66] loss: 45.2561 PSNR_train: 13.8324\n",
            "[epoch 2][53/66] loss: 35.3549 PSNR_train: 14.0992\n",
            "[epoch 2][54/66] loss: 37.0760 PSNR_train: 13.7885\n",
            "[epoch 2][55/66] loss: 38.5914 PSNR_train: 13.9544\n",
            "[epoch 2][56/66] loss: 41.7029 PSNR_train: 13.7470\n",
            "[epoch 2][57/66] loss: 32.9845 PSNR_train: 14.0568\n",
            "[epoch 2][58/66] loss: 42.3707 PSNR_train: 14.1926\n",
            "[epoch 2][59/66] loss: 37.2711 PSNR_train: 14.0936\n",
            "[epoch 2][60/66] loss: 35.1078 PSNR_train: 13.9335\n",
            "[epoch 2][61/66] loss: 32.7888 PSNR_train: 14.2781\n",
            "[epoch 2][62/66] loss: 27.7740 PSNR_train: 14.8165\n",
            "[epoch 2][63/66] loss: 29.2563 PSNR_train: 14.7920\n",
            "[epoch 2][64/66] loss: 31.0752 PSNR_train: 14.7879\n",
            "[epoch 2][65/66] loss: 28.5454 PSNR_train: 14.6383\n",
            "[epoch 2][66/66] loss: 11.3851 PSNR_train: 15.5300\n",
            "\n",
            "[epoch 2] PSNR_val: 15.8927\n",
            "learning rate 0.000100\n",
            "[epoch 3][1/66] loss: 31.4185 PSNR_train: 15.3937\n",
            "[epoch 3][2/66] loss: 26.5111 PSNR_train: 15.0507\n",
            "[epoch 3][3/66] loss: 24.5199 PSNR_train: 15.2634\n",
            "[epoch 3][4/66] loss: 24.3974 PSNR_train: 15.2773\n",
            "[epoch 3][5/66] loss: 29.2794 PSNR_train: 15.1091\n",
            "[epoch 3][6/66] loss: 29.4029 PSNR_train: 15.0280\n",
            "[epoch 3][7/66] loss: 29.5354 PSNR_train: 15.3506\n",
            "[epoch 3][8/66] loss: 18.2353 PSNR_train: 15.6644\n",
            "[epoch 3][9/66] loss: 25.4800 PSNR_train: 15.7679\n",
            "[epoch 3][10/66] loss: 24.9702 PSNR_train: 15.9587\n",
            "[epoch 3][11/66] loss: 26.2590 PSNR_train: 15.8302\n",
            "[epoch 3][12/66] loss: 26.8758 PSNR_train: 15.9563\n",
            "[epoch 3][13/66] loss: 23.1492 PSNR_train: 15.8097\n",
            "[epoch 3][14/66] loss: 20.0845 PSNR_train: 15.8150\n",
            "[epoch 3][15/66] loss: 16.5759 PSNR_train: 16.1572\n",
            "[epoch 3][16/66] loss: 27.3163 PSNR_train: 16.0079\n",
            "[epoch 3][17/66] loss: 12.8221 PSNR_train: 16.6599\n",
            "[epoch 3][18/66] loss: 26.4067 PSNR_train: 16.2692\n",
            "[epoch 3][19/66] loss: 21.8815 PSNR_train: 16.3372\n",
            "[epoch 3][20/66] loss: 20.9315 PSNR_train: 16.4196\n",
            "[epoch 3][21/66] loss: 21.2277 PSNR_train: 16.8973\n",
            "[epoch 3][22/66] loss: 20.0103 PSNR_train: 16.6200\n",
            "[epoch 3][23/66] loss: 19.4606 PSNR_train: 16.5688\n",
            "[epoch 3][24/66] loss: 15.6606 PSNR_train: 16.7356\n",
            "[epoch 3][25/66] loss: 18.4090 PSNR_train: 16.7758\n",
            "[epoch 3][26/66] loss: 16.4944 PSNR_train: 16.9668\n",
            "[epoch 3][27/66] loss: 13.1342 PSNR_train: 17.0778\n",
            "[epoch 3][28/66] loss: 14.4556 PSNR_train: 17.1767\n",
            "[epoch 3][29/66] loss: 15.0556 PSNR_train: 17.1178\n",
            "[epoch 3][30/66] loss: 15.6108 PSNR_train: 17.3878\n",
            "[epoch 3][31/66] loss: 12.7668 PSNR_train: 17.5327\n",
            "[epoch 3][32/66] loss: 18.6762 PSNR_train: 17.6199\n",
            "[epoch 3][33/66] loss: 12.4309 PSNR_train: 17.6213\n",
            "[epoch 3][34/66] loss: 12.1735 PSNR_train: 17.8282\n",
            "[epoch 3][35/66] loss: 15.3140 PSNR_train: 18.0582\n",
            "[epoch 3][36/66] loss: 14.2809 PSNR_train: 18.0516\n",
            "[epoch 3][37/66] loss: 17.6314 PSNR_train: 18.3019\n",
            "[epoch 3][38/66] loss: 16.4470 PSNR_train: 18.0217\n",
            "[epoch 3][39/66] loss: 13.6128 PSNR_train: 18.3655\n",
            "[epoch 3][40/66] loss: 12.9758 PSNR_train: 18.3530\n",
            "[epoch 3][41/66] loss: 9.7816 PSNR_train: 18.6838\n",
            "[epoch 3][42/66] loss: 6.3271 PSNR_train: 18.8461\n",
            "[epoch 3][43/66] loss: 12.2662 PSNR_train: 19.2973\n",
            "[epoch 3][44/66] loss: 11.5876 PSNR_train: 18.9294\n",
            "[epoch 3][45/66] loss: 8.2220 PSNR_train: 19.4296\n",
            "[epoch 3][46/66] loss: 6.4694 PSNR_train: 19.5959\n",
            "[epoch 3][47/66] loss: 6.3855 PSNR_train: 19.7736\n",
            "[epoch 3][48/66] loss: 9.6858 PSNR_train: 19.7923\n",
            "[epoch 3][49/66] loss: 13.6077 PSNR_train: 19.4033\n",
            "[epoch 3][50/66] loss: 11.3927 PSNR_train: 19.7748\n",
            "[epoch 3][51/66] loss: 11.7925 PSNR_train: 19.7468\n",
            "[epoch 3][52/66] loss: 5.7238 PSNR_train: 20.2926\n",
            "[epoch 3][53/66] loss: 10.2193 PSNR_train: 20.0564\n",
            "[epoch 3][54/66] loss: 10.3659 PSNR_train: 20.1893\n",
            "[epoch 3][55/66] loss: 12.0352 PSNR_train: 20.0616\n",
            "[epoch 3][56/66] loss: 8.0681 PSNR_train: 20.1733\n",
            "[epoch 3][57/66] loss: 6.3299 PSNR_train: 20.5541\n",
            "[epoch 3][58/66] loss: 9.5457 PSNR_train: 20.4593\n",
            "[epoch 3][59/66] loss: 9.6599 PSNR_train: 20.4613\n",
            "[epoch 3][60/66] loss: 11.4540 PSNR_train: 20.4832\n",
            "[epoch 3][61/66] loss: 5.4448 PSNR_train: 21.0516\n",
            "[epoch 3][62/66] loss: 4.4890 PSNR_train: 21.4599\n",
            "[epoch 3][63/66] loss: 8.7755 PSNR_train: 21.1049\n",
            "[epoch 3][64/66] loss: 5.8904 PSNR_train: 21.3918\n",
            "[epoch 3][65/66] loss: 6.0978 PSNR_train: 21.6387\n",
            "[epoch 3][66/66] loss: 11.0488 PSNR_train: 21.9372\n",
            "\n",
            "[epoch 3] PSNR_val: 20.4903\n",
            "learning rate 0.000100\n",
            "[epoch 4][1/66] loss: 5.7401 PSNR_train: 21.3073\n",
            "[epoch 4][2/66] loss: 4.9004 PSNR_train: 21.6272\n",
            "[epoch 4][3/66] loss: 5.4607 PSNR_train: 21.7395\n",
            "[epoch 4][4/66] loss: 9.2713 PSNR_train: 21.7594\n",
            "[epoch 4][5/66] loss: 5.8758 PSNR_train: 22.1014\n",
            "[epoch 4][6/66] loss: 7.3913 PSNR_train: 22.0219\n",
            "[epoch 4][7/66] loss: 7.8158 PSNR_train: 21.6925\n",
            "[epoch 4][8/66] loss: 6.6060 PSNR_train: 21.8608\n",
            "[epoch 4][9/66] loss: 6.4379 PSNR_train: 21.7415\n",
            "[epoch 4][10/66] loss: 5.5459 PSNR_train: 22.5197\n",
            "[epoch 4][11/66] loss: 8.7245 PSNR_train: 22.6560\n",
            "[epoch 4][12/66] loss: 4.6482 PSNR_train: 22.3012\n",
            "[epoch 4][13/66] loss: 6.0955 PSNR_train: 22.2906\n",
            "[epoch 4][14/66] loss: 5.5507 PSNR_train: 22.5362\n",
            "[epoch 4][15/66] loss: 5.1867 PSNR_train: 23.0257\n",
            "[epoch 4][16/66] loss: 8.3187 PSNR_train: 22.8354\n",
            "[epoch 4][17/66] loss: 7.2742 PSNR_train: 22.3968\n",
            "[epoch 4][18/66] loss: 4.6045 PSNR_train: 22.8671\n",
            "[epoch 4][19/66] loss: 5.5009 PSNR_train: 22.6067\n",
            "[epoch 4][20/66] loss: 5.4627 PSNR_train: 22.7885\n",
            "[epoch 4][21/66] loss: 6.5413 PSNR_train: 22.6674\n",
            "[epoch 4][22/66] loss: 5.4885 PSNR_train: 23.2735\n",
            "[epoch 4][23/66] loss: 3.4200 PSNR_train: 23.3659\n",
            "[epoch 4][24/66] loss: 4.2028 PSNR_train: 23.1286\n",
            "[epoch 4][25/66] loss: 5.2607 PSNR_train: 23.3883\n",
            "[epoch 4][26/66] loss: 6.6737 PSNR_train: 23.1639\n",
            "[epoch 4][27/66] loss: 4.2666 PSNR_train: 23.2754\n",
            "[epoch 4][28/66] loss: 3.5342 PSNR_train: 23.1526\n",
            "[epoch 4][29/66] loss: 2.8084 PSNR_train: 23.7293\n",
            "[epoch 4][30/66] loss: 3.5684 PSNR_train: 23.5726\n",
            "[epoch 4][31/66] loss: 4.8731 PSNR_train: 23.9191\n",
            "[epoch 4][32/66] loss: 4.3078 PSNR_train: 23.6643\n",
            "[epoch 4][33/66] loss: 3.2944 PSNR_train: 24.0057\n",
            "[epoch 4][34/66] loss: 4.3251 PSNR_train: 23.6465\n",
            "[epoch 4][35/66] loss: 3.7822 PSNR_train: 24.2749\n",
            "[epoch 4][36/66] loss: 4.7669 PSNR_train: 24.4705\n",
            "[epoch 4][37/66] loss: 2.7281 PSNR_train: 24.2067\n",
            "[epoch 4][38/66] loss: 2.7062 PSNR_train: 24.3900\n",
            "[epoch 4][39/66] loss: 3.2427 PSNR_train: 24.4957\n",
            "[epoch 4][40/66] loss: 2.3657 PSNR_train: 25.2987\n",
            "[epoch 4][41/66] loss: 2.4222 PSNR_train: 25.2277\n",
            "[epoch 4][42/66] loss: 2.9616 PSNR_train: 25.1809\n",
            "[epoch 4][43/66] loss: 2.1493 PSNR_train: 25.5875\n",
            "[epoch 4][44/66] loss: 2.7430 PSNR_train: 25.4471\n",
            "[epoch 4][45/66] loss: 2.5906 PSNR_train: 25.3503\n",
            "[epoch 4][46/66] loss: 4.2734 PSNR_train: 24.9062\n",
            "[epoch 4][47/66] loss: 2.7203 PSNR_train: 25.0378\n",
            "[epoch 4][48/66] loss: 2.4223 PSNR_train: 25.2071\n",
            "[epoch 4][49/66] loss: 3.9932 PSNR_train: 25.2456\n",
            "[epoch 4][50/66] loss: 2.7235 PSNR_train: 25.2442\n",
            "[epoch 4][51/66] loss: 2.3537 PSNR_train: 25.3707\n",
            "[epoch 4][52/66] loss: 3.8522 PSNR_train: 25.4044\n",
            "[epoch 4][53/66] loss: 2.2169 PSNR_train: 25.5404\n",
            "[epoch 4][54/66] loss: 2.4216 PSNR_train: 25.9077\n",
            "[epoch 4][55/66] loss: 2.7559 PSNR_train: 26.2385\n",
            "[epoch 4][56/66] loss: 3.6323 PSNR_train: 25.6806\n",
            "[epoch 4][57/66] loss: 2.7348 PSNR_train: 24.8257\n",
            "[epoch 4][58/66] loss: 2.6134 PSNR_train: 25.4272\n",
            "[epoch 4][59/66] loss: 2.5317 PSNR_train: 25.9174\n",
            "[epoch 4][60/66] loss: 4.1096 PSNR_train: 25.0425\n",
            "[epoch 4][61/66] loss: 2.9184 PSNR_train: 25.4010\n",
            "[epoch 4][62/66] loss: 2.7300 PSNR_train: 25.6742\n",
            "[epoch 4][63/66] loss: 2.4218 PSNR_train: 25.7653\n",
            "[epoch 4][64/66] loss: 2.1801 PSNR_train: 26.3904\n",
            "[epoch 4][65/66] loss: 2.5804 PSNR_train: 25.6937\n",
            "[epoch 4][66/66] loss: 12.0076 PSNR_train: 24.5798\n",
            "\n",
            "[epoch 4] PSNR_val: 24.6898\n",
            "learning rate 0.000100\n",
            "[epoch 5][1/66] loss: 4.5245 PSNR_train: 25.2216\n",
            "[epoch 5][2/66] loss: 2.5524 PSNR_train: 25.3388\n",
            "[epoch 5][3/66] loss: 2.2016 PSNR_train: 26.2389\n",
            "[epoch 5][4/66] loss: 3.5992 PSNR_train: 25.9082\n",
            "[epoch 5][5/66] loss: 2.9722 PSNR_train: 25.0007\n",
            "[epoch 5][6/66] loss: 2.2640 PSNR_train: 25.6008\n",
            "[epoch 5][7/66] loss: 3.0533 PSNR_train: 25.5609\n",
            "[epoch 5][8/66] loss: 3.7783 PSNR_train: 25.3449\n",
            "[epoch 5][9/66] loss: 2.0704 PSNR_train: 25.7782\n",
            "[epoch 5][10/66] loss: 2.2631 PSNR_train: 26.0207\n",
            "[epoch 5][11/66] loss: 2.7594 PSNR_train: 26.1158\n",
            "[epoch 5][12/66] loss: 2.4872 PSNR_train: 26.5202\n",
            "[epoch 5][13/66] loss: 2.5486 PSNR_train: 26.5702\n",
            "[epoch 5][14/66] loss: 2.0029 PSNR_train: 26.8959\n",
            "[epoch 5][15/66] loss: 2.6298 PSNR_train: 26.1202\n",
            "[epoch 5][16/66] loss: 2.1953 PSNR_train: 26.4022\n",
            "[epoch 5][17/66] loss: 2.6339 PSNR_train: 26.6804\n",
            "[epoch 5][18/66] loss: 3.8414 PSNR_train: 26.5771\n",
            "[epoch 5][19/66] loss: 2.5201 PSNR_train: 25.8984\n",
            "[epoch 5][20/66] loss: 2.4059 PSNR_train: 26.9265\n",
            "[epoch 5][21/66] loss: 3.1467 PSNR_train: 26.1629\n",
            "[epoch 5][22/66] loss: 2.2604 PSNR_train: 26.4268\n",
            "[epoch 5][23/66] loss: 2.4354 PSNR_train: 26.4306\n",
            "[epoch 5][24/66] loss: 2.3283 PSNR_train: 26.3836\n",
            "[epoch 5][25/66] loss: 2.3543 PSNR_train: 26.3387\n",
            "[epoch 5][26/66] loss: 1.9960 PSNR_train: 26.9157\n",
            "[epoch 5][27/66] loss: 2.8729 PSNR_train: 26.2755\n",
            "[epoch 5][28/66] loss: 2.1549 PSNR_train: 27.1336\n",
            "[epoch 5][29/66] loss: 3.2890 PSNR_train: 26.6755\n",
            "[epoch 5][30/66] loss: 2.5898 PSNR_train: 26.3411\n",
            "[epoch 5][31/66] loss: 2.7564 PSNR_train: 26.0732\n",
            "[epoch 5][32/66] loss: 2.6713 PSNR_train: 26.0115\n",
            "[epoch 5][33/66] loss: 1.9978 PSNR_train: 26.7295\n",
            "[epoch 5][34/66] loss: 2.1606 PSNR_train: 26.6124\n",
            "[epoch 5][35/66] loss: 1.9849 PSNR_train: 26.8060\n",
            "[epoch 5][36/66] loss: 2.3394 PSNR_train: 27.1419\n",
            "[epoch 5][37/66] loss: 2.0313 PSNR_train: 26.9360\n",
            "[epoch 5][38/66] loss: 2.1361 PSNR_train: 26.7498\n",
            "[epoch 5][39/66] loss: 2.1825 PSNR_train: 27.1217\n",
            "[epoch 5][40/66] loss: 3.1322 PSNR_train: 26.4977\n",
            "[epoch 5][41/66] loss: 2.5401 PSNR_train: 27.4361\n",
            "[epoch 5][42/66] loss: 2.2642 PSNR_train: 26.6092\n",
            "[epoch 5][43/66] loss: 1.8182 PSNR_train: 27.1431\n",
            "[epoch 5][44/66] loss: 2.0517 PSNR_train: 27.0035\n",
            "[epoch 5][45/66] loss: 2.3810 PSNR_train: 26.2998\n",
            "[epoch 5][46/66] loss: 2.1824 PSNR_train: 26.4204\n",
            "[epoch 5][47/66] loss: 2.2997 PSNR_train: 26.8190\n",
            "[epoch 5][48/66] loss: 2.1096 PSNR_train: 26.7306\n",
            "[epoch 5][49/66] loss: 2.2340 PSNR_train: 26.9296\n",
            "[epoch 5][50/66] loss: 2.1026 PSNR_train: 26.9648\n",
            "[epoch 5][51/66] loss: 2.8574 PSNR_train: 26.5022\n",
            "[epoch 5][52/66] loss: 1.9031 PSNR_train: 27.3343\n",
            "[epoch 5][53/66] loss: 2.2524 PSNR_train: 26.4845\n",
            "[epoch 5][54/66] loss: 2.3163 PSNR_train: 27.1711\n",
            "[epoch 5][55/66] loss: 1.9551 PSNR_train: 27.0608\n",
            "[epoch 5][56/66] loss: 2.6306 PSNR_train: 26.1479\n",
            "[epoch 5][57/66] loss: 2.1606 PSNR_train: 26.6576\n",
            "[epoch 5][58/66] loss: 2.0612 PSNR_train: 27.3569\n",
            "[epoch 5][59/66] loss: 5.2021 PSNR_train: 26.9510\n",
            "[epoch 5][60/66] loss: 2.6282 PSNR_train: 27.2707\n",
            "[epoch 5][61/66] loss: 2.5380 PSNR_train: 26.8234\n",
            "[epoch 5][62/66] loss: 3.2976 PSNR_train: 26.6507\n",
            "[epoch 5][63/66] loss: 2.2930 PSNR_train: 27.3641\n",
            "[epoch 5][64/66] loss: 2.3070 PSNR_train: 26.6623\n",
            "[epoch 5][65/66] loss: 2.0144 PSNR_train: 27.4254\n",
            "[epoch 5][66/66] loss: 2.4084 PSNR_train: 26.3966\n",
            "\n",
            "[epoch 5] PSNR_val: 25.6241\n",
            "learning rate 0.000100\n",
            "[epoch 6][1/66] loss: 2.2077 PSNR_train: 26.7816\n",
            "[epoch 6][2/66] loss: 2.6601 PSNR_train: 27.2508\n",
            "[epoch 6][3/66] loss: 2.4417 PSNR_train: 27.4491\n",
            "[epoch 6][4/66] loss: 2.1787 PSNR_train: 26.9525\n",
            "[epoch 6][5/66] loss: 2.1828 PSNR_train: 27.6556\n",
            "[epoch 6][6/66] loss: 2.0767 PSNR_train: 27.2180\n",
            "[epoch 6][7/66] loss: 2.4134 PSNR_train: 27.4666\n",
            "[epoch 6][8/66] loss: 2.4273 PSNR_train: 26.6208\n",
            "[epoch 6][9/66] loss: 2.0703 PSNR_train: 27.0667\n",
            "[epoch 6][10/66] loss: 2.3215 PSNR_train: 26.6931\n",
            "[epoch 6][11/66] loss: 2.0635 PSNR_train: 27.4250\n",
            "[epoch 6][12/66] loss: 2.1583 PSNR_train: 27.0101\n",
            "[epoch 6][13/66] loss: 2.0392 PSNR_train: 27.1750\n",
            "[epoch 6][14/66] loss: 2.3369 PSNR_train: 26.9155\n",
            "[epoch 6][15/66] loss: 2.3619 PSNR_train: 26.7067\n",
            "[epoch 6][16/66] loss: 1.9602 PSNR_train: 27.6100\n",
            "[epoch 6][17/66] loss: 2.4283 PSNR_train: 26.2869\n",
            "[epoch 6][18/66] loss: 2.4881 PSNR_train: 26.6031\n",
            "[epoch 6][19/66] loss: 2.1359 PSNR_train: 26.9872\n",
            "[epoch 6][20/66] loss: 1.9627 PSNR_train: 27.3369\n",
            "[epoch 6][21/66] loss: 2.3015 PSNR_train: 27.3195\n",
            "[epoch 6][22/66] loss: 2.1607 PSNR_train: 27.3318\n",
            "[epoch 6][23/66] loss: 2.3693 PSNR_train: 27.1174\n",
            "[epoch 6][24/66] loss: 2.8986 PSNR_train: 27.2358\n",
            "[epoch 6][25/66] loss: 2.4533 PSNR_train: 27.2053\n",
            "[epoch 6][26/66] loss: 1.7097 PSNR_train: 27.1104\n",
            "[epoch 6][27/66] loss: 2.4003 PSNR_train: 26.4827\n",
            "[epoch 6][28/66] loss: 1.8650 PSNR_train: 27.2420\n",
            "[epoch 6][29/66] loss: 2.3979 PSNR_train: 26.5867\n",
            "[epoch 6][30/66] loss: 1.9967 PSNR_train: 27.3360\n",
            "[epoch 6][31/66] loss: 2.0929 PSNR_train: 27.0003\n",
            "[epoch 6][32/66] loss: 2.1850 PSNR_train: 27.0162\n",
            "[epoch 6][33/66] loss: 2.3427 PSNR_train: 27.1114\n",
            "[epoch 6][34/66] loss: 2.0262 PSNR_train: 27.1582\n",
            "[epoch 6][35/66] loss: 2.1814 PSNR_train: 27.0547\n",
            "[epoch 6][36/66] loss: 1.9926 PSNR_train: 27.1541\n",
            "[epoch 6][37/66] loss: 1.9529 PSNR_train: 27.1635\n",
            "[epoch 6][38/66] loss: 1.7668 PSNR_train: 27.9200\n",
            "[epoch 6][39/66] loss: 1.8662 PSNR_train: 27.4271\n",
            "[epoch 6][40/66] loss: 2.3867 PSNR_train: 26.6709\n",
            "[epoch 6][41/66] loss: 2.4804 PSNR_train: 26.9366\n",
            "[epoch 6][42/66] loss: 2.1888 PSNR_train: 27.5511\n",
            "[epoch 6][43/66] loss: 1.9039 PSNR_train: 27.3211\n",
            "[epoch 6][44/66] loss: 1.7521 PSNR_train: 27.8899\n",
            "[epoch 6][45/66] loss: 1.9070 PSNR_train: 27.2833\n",
            "[epoch 6][46/66] loss: 1.9981 PSNR_train: 27.5194\n",
            "[epoch 6][47/66] loss: 1.9363 PSNR_train: 27.7418\n",
            "[epoch 6][48/66] loss: 2.5382 PSNR_train: 27.5886\n",
            "[epoch 6][49/66] loss: 2.2534 PSNR_train: 27.2007\n",
            "[epoch 6][50/66] loss: 2.3156 PSNR_train: 27.9243\n",
            "[epoch 6][51/66] loss: 2.1727 PSNR_train: 26.7933\n",
            "[epoch 6][52/66] loss: 2.6545 PSNR_train: 26.6165\n",
            "[epoch 6][53/66] loss: 2.8352 PSNR_train: 27.1265\n",
            "[epoch 6][54/66] loss: 2.0541 PSNR_train: 27.4713\n",
            "[epoch 6][55/66] loss: 2.0096 PSNR_train: 27.3386\n",
            "[epoch 6][56/66] loss: 2.0455 PSNR_train: 27.4730\n",
            "[epoch 6][57/66] loss: 2.1789 PSNR_train: 26.9923\n",
            "[epoch 6][58/66] loss: 1.9980 PSNR_train: 27.1216\n",
            "[epoch 6][59/66] loss: 2.0425 PSNR_train: 26.6084\n",
            "[epoch 6][60/66] loss: 2.6186 PSNR_train: 26.3336\n",
            "[epoch 6][61/66] loss: 2.5754 PSNR_train: 26.4419\n",
            "[epoch 6][62/66] loss: 1.9595 PSNR_train: 26.7128\n",
            "[epoch 6][63/66] loss: 2.2394 PSNR_train: 26.5483\n",
            "[epoch 6][64/66] loss: 2.1789 PSNR_train: 26.4319\n",
            "[epoch 6][65/66] loss: 2.0954 PSNR_train: 27.7057\n",
            "[epoch 6][66/66] loss: 4.2328 PSNR_train: 26.7284\n",
            "\n",
            "[epoch 6] PSNR_val: 25.0273\n",
            "learning rate 0.000100\n",
            "[epoch 7][1/66] loss: 1.8798 PSNR_train: 27.4685\n",
            "[epoch 7][2/66] loss: 2.0911 PSNR_train: 27.1763\n",
            "[epoch 7][3/66] loss: 1.9547 PSNR_train: 27.4076\n",
            "[epoch 7][4/66] loss: 2.4039 PSNR_train: 26.6408\n",
            "[epoch 7][5/66] loss: 1.8186 PSNR_train: 27.1571\n",
            "[epoch 7][6/66] loss: 2.0224 PSNR_train: 26.8415\n",
            "[epoch 7][7/66] loss: 2.0625 PSNR_train: 26.5787\n",
            "[epoch 7][8/66] loss: 1.8090 PSNR_train: 26.9690\n",
            "[epoch 7][9/66] loss: 3.4293 PSNR_train: 26.3152\n",
            "[epoch 7][10/66] loss: 2.9292 PSNR_train: 26.9303\n",
            "[epoch 7][11/66] loss: 2.2290 PSNR_train: 27.3687\n",
            "[epoch 7][12/66] loss: 2.6242 PSNR_train: 26.2563\n",
            "[epoch 7][13/66] loss: 2.5982 PSNR_train: 26.5569\n",
            "[epoch 7][14/66] loss: 3.3652 PSNR_train: 25.9919\n",
            "[epoch 7][15/66] loss: 2.5704 PSNR_train: 26.9880\n",
            "[epoch 7][16/66] loss: 2.2201 PSNR_train: 27.3089\n",
            "[epoch 7][17/66] loss: 2.0621 PSNR_train: 27.5307\n",
            "[epoch 7][18/66] loss: 1.8018 PSNR_train: 27.2356\n",
            "[epoch 7][19/66] loss: 1.8161 PSNR_train: 27.0138\n",
            "[epoch 7][20/66] loss: 2.8693 PSNR_train: 26.6198\n",
            "[epoch 7][21/66] loss: 3.1289 PSNR_train: 26.1045\n",
            "[epoch 7][22/66] loss: 2.1992 PSNR_train: 26.4327\n",
            "[epoch 7][23/66] loss: 2.0924 PSNR_train: 27.2667\n",
            "[epoch 7][24/66] loss: 2.4301 PSNR_train: 27.4345\n",
            "[epoch 7][25/66] loss: 2.3421 PSNR_train: 26.7200\n",
            "[epoch 7][26/66] loss: 2.2691 PSNR_train: 26.8384\n",
            "[epoch 7][27/66] loss: 1.9250 PSNR_train: 26.5592\n",
            "[epoch 7][28/66] loss: 2.7288 PSNR_train: 26.0259\n",
            "[epoch 7][29/66] loss: 1.8403 PSNR_train: 26.8331\n",
            "[epoch 7][30/66] loss: 2.7496 PSNR_train: 26.6791\n",
            "[epoch 7][31/66] loss: 3.2872 PSNR_train: 27.2437\n",
            "[epoch 7][32/66] loss: 2.6805 PSNR_train: 26.5284\n",
            "[epoch 7][33/66] loss: 1.9496 PSNR_train: 26.1352\n",
            "[epoch 7][34/66] loss: 2.2573 PSNR_train: 25.4182\n",
            "[epoch 7][35/66] loss: 2.8851 PSNR_train: 25.9984\n",
            "[epoch 7][36/66] loss: 2.5687 PSNR_train: 26.2731\n",
            "[epoch 7][37/66] loss: 2.8848 PSNR_train: 26.3971\n",
            "[epoch 7][38/66] loss: 3.2130 PSNR_train: 27.2643\n",
            "[epoch 7][39/66] loss: 2.0487 PSNR_train: 27.1609\n",
            "[epoch 7][40/66] loss: 2.1179 PSNR_train: 27.2767\n",
            "[epoch 7][41/66] loss: 2.0933 PSNR_train: 27.1494\n",
            "[epoch 7][42/66] loss: 2.5487 PSNR_train: 27.1909\n",
            "[epoch 7][43/66] loss: 2.2171 PSNR_train: 27.0910\n",
            "[epoch 7][44/66] loss: 2.2134 PSNR_train: 27.5380\n",
            "[epoch 7][45/66] loss: 2.0340 PSNR_train: 27.7819\n",
            "[epoch 7][46/66] loss: 1.9456 PSNR_train: 27.2169\n",
            "[epoch 7][47/66] loss: 1.6891 PSNR_train: 28.1350\n",
            "[epoch 7][48/66] loss: 2.5134 PSNR_train: 26.4630\n",
            "[epoch 7][49/66] loss: 2.7810 PSNR_train: 27.6827\n",
            "[epoch 7][50/66] loss: 2.5336 PSNR_train: 26.6227\n",
            "[epoch 7][51/66] loss: 2.1137 PSNR_train: 27.1814\n",
            "[epoch 7][52/66] loss: 2.0613 PSNR_train: 27.2590\n",
            "[epoch 7][53/66] loss: 2.7821 PSNR_train: 28.0129\n",
            "[epoch 7][54/66] loss: 1.9165 PSNR_train: 26.9690\n",
            "[epoch 7][55/66] loss: 1.8135 PSNR_train: 27.3066\n",
            "[epoch 7][56/66] loss: 1.8662 PSNR_train: 27.4930\n",
            "[epoch 7][57/66] loss: 2.5727 PSNR_train: 26.6884\n",
            "[epoch 7][58/66] loss: 1.8491 PSNR_train: 27.5847\n",
            "[epoch 7][59/66] loss: 1.9939 PSNR_train: 27.5012\n",
            "[epoch 7][60/66] loss: 2.1473 PSNR_train: 27.6563\n",
            "[epoch 7][61/66] loss: 2.4604 PSNR_train: 27.4105\n",
            "[epoch 7][62/66] loss: 1.9115 PSNR_train: 27.3416\n",
            "[epoch 7][63/66] loss: 1.7564 PSNR_train: 27.6412\n",
            "[epoch 7][64/66] loss: 1.8786 PSNR_train: 27.6311\n",
            "[epoch 7][65/66] loss: 1.9697 PSNR_train: 27.9600\n",
            "[epoch 7][66/66] loss: 3.3053 PSNR_train: 27.4688\n",
            "\n",
            "[epoch 7] PSNR_val: 26.0986\n",
            "learning rate 0.000100\n",
            "[epoch 8][1/66] loss: 1.9831 PSNR_train: 27.0924\n",
            "[epoch 8][2/66] loss: 1.8253 PSNR_train: 27.6872\n",
            "[epoch 8][3/66] loss: 2.0074 PSNR_train: 27.3258\n",
            "[epoch 8][4/66] loss: 2.1189 PSNR_train: 27.3864\n",
            "[epoch 8][5/66] loss: 2.5863 PSNR_train: 26.2907\n",
            "[epoch 8][6/66] loss: 1.9591 PSNR_train: 27.6677\n",
            "[epoch 8][7/66] loss: 2.0647 PSNR_train: 27.4753\n",
            "[epoch 8][8/66] loss: 2.0948 PSNR_train: 27.3212\n",
            "[epoch 8][9/66] loss: 1.8170 PSNR_train: 27.7439\n",
            "[epoch 8][10/66] loss: 2.6028 PSNR_train: 27.3171\n",
            "[epoch 8][11/66] loss: 2.3310 PSNR_train: 27.5349\n",
            "[epoch 8][12/66] loss: 1.8161 PSNR_train: 27.6258\n",
            "[epoch 8][13/66] loss: 2.1480 PSNR_train: 26.7974\n",
            "[epoch 8][14/66] loss: 2.1391 PSNR_train: 26.7486\n",
            "[epoch 8][15/66] loss: 1.7872 PSNR_train: 27.6272\n",
            "[epoch 8][16/66] loss: 1.9811 PSNR_train: 27.5342\n",
            "[epoch 8][17/66] loss: 2.3257 PSNR_train: 27.4254\n",
            "[epoch 8][18/66] loss: 2.1411 PSNR_train: 27.2207\n",
            "[epoch 8][19/66] loss: 2.1177 PSNR_train: 27.6234\n",
            "[epoch 8][20/66] loss: 2.2534 PSNR_train: 27.3561\n",
            "[epoch 8][21/66] loss: 2.0042 PSNR_train: 27.4779\n",
            "[epoch 8][22/66] loss: 2.1641 PSNR_train: 27.2057\n",
            "[epoch 8][23/66] loss: 1.8095 PSNR_train: 27.6724\n",
            "[epoch 8][24/66] loss: 1.9411 PSNR_train: 27.3254\n",
            "[epoch 8][25/66] loss: 2.3037 PSNR_train: 27.0343\n",
            "[epoch 8][26/66] loss: 2.0918 PSNR_train: 27.4897\n",
            "[epoch 8][27/66] loss: 1.8596 PSNR_train: 27.2937\n",
            "[epoch 8][28/66] loss: 1.8242 PSNR_train: 27.9284\n",
            "[epoch 8][29/66] loss: 1.9871 PSNR_train: 27.8411\n",
            "[epoch 8][30/66] loss: 2.0315 PSNR_train: 27.1598\n",
            "[epoch 8][31/66] loss: 1.9651 PSNR_train: 27.7958\n",
            "[epoch 8][32/66] loss: 1.6163 PSNR_train: 28.0485\n",
            "[epoch 8][33/66] loss: 1.9142 PSNR_train: 27.9704\n",
            "[epoch 8][34/66] loss: 1.7726 PSNR_train: 27.8523\n",
            "[epoch 8][35/66] loss: 2.0007 PSNR_train: 27.3651\n",
            "[epoch 8][36/66] loss: 2.1725 PSNR_train: 27.8479\n",
            "[epoch 8][37/66] loss: 2.9201 PSNR_train: 28.2722\n",
            "[epoch 8][38/66] loss: 2.0174 PSNR_train: 27.5035\n",
            "[epoch 8][39/66] loss: 1.7314 PSNR_train: 28.3115\n",
            "[epoch 8][40/66] loss: 1.7628 PSNR_train: 27.7908\n",
            "[epoch 8][41/66] loss: 1.7385 PSNR_train: 27.9125\n",
            "[epoch 8][42/66] loss: 2.1808 PSNR_train: 27.4889\n",
            "[epoch 8][43/66] loss: 2.2844 PSNR_train: 27.6634\n",
            "[epoch 8][44/66] loss: 1.7444 PSNR_train: 28.2726\n",
            "[epoch 8][45/66] loss: 1.6763 PSNR_train: 28.4479\n",
            "[epoch 8][46/66] loss: 1.6919 PSNR_train: 27.8147\n",
            "[epoch 8][47/66] loss: 2.3337 PSNR_train: 26.5194\n",
            "[epoch 8][48/66] loss: 1.8581 PSNR_train: 27.6017\n",
            "[epoch 8][49/66] loss: 2.6435 PSNR_train: 27.1756\n",
            "[epoch 8][50/66] loss: 2.0711 PSNR_train: 27.5962\n",
            "[epoch 8][51/66] loss: 1.7705 PSNR_train: 27.9768\n",
            "[epoch 8][52/66] loss: 1.9816 PSNR_train: 27.2855\n",
            "[epoch 8][53/66] loss: 1.8889 PSNR_train: 27.5386\n",
            "[epoch 8][54/66] loss: 1.9566 PSNR_train: 27.6362\n",
            "[epoch 8][55/66] loss: 3.0433 PSNR_train: 27.4831\n",
            "[epoch 8][56/66] loss: 2.0605 PSNR_train: 27.4146\n",
            "[epoch 8][57/66] loss: 2.5527 PSNR_train: 26.9539\n",
            "[epoch 8][58/66] loss: 2.5007 PSNR_train: 28.6284\n",
            "[epoch 8][59/66] loss: 2.9749 PSNR_train: 27.4247\n",
            "[epoch 8][60/66] loss: 2.5719 PSNR_train: 27.3076\n",
            "[epoch 8][61/66] loss: 2.6245 PSNR_train: 27.2756\n",
            "[epoch 8][62/66] loss: 2.5196 PSNR_train: 27.1302\n",
            "[epoch 8][63/66] loss: 1.7708 PSNR_train: 27.4028\n",
            "[epoch 8][64/66] loss: 1.7292 PSNR_train: 27.9472\n",
            "[epoch 8][65/66] loss: 1.6143 PSNR_train: 27.8397\n",
            "[epoch 8][66/66] loss: 3.9709 PSNR_train: 27.6214\n",
            "\n",
            "[epoch 8] PSNR_val: 26.4055\n",
            "learning rate 0.000100\n",
            "[epoch 9][1/66] loss: 1.7841 PSNR_train: 27.6595\n",
            "[epoch 9][2/66] loss: 2.1991 PSNR_train: 27.6858\n",
            "[epoch 9][3/66] loss: 2.4239 PSNR_train: 27.0945\n",
            "[epoch 9][4/66] loss: 1.6951 PSNR_train: 27.5437\n",
            "[epoch 9][5/66] loss: 2.2609 PSNR_train: 27.3877\n",
            "[epoch 9][6/66] loss: 2.0761 PSNR_train: 27.3891\n",
            "[epoch 9][7/66] loss: 1.7868 PSNR_train: 27.5352\n",
            "[epoch 9][8/66] loss: 1.7098 PSNR_train: 27.5559\n",
            "[epoch 9][9/66] loss: 3.0739 PSNR_train: 27.8309\n",
            "[epoch 9][10/66] loss: 1.9088 PSNR_train: 27.6451\n",
            "[epoch 9][11/66] loss: 1.9041 PSNR_train: 27.6766\n",
            "[epoch 9][12/66] loss: 2.5838 PSNR_train: 27.4460\n",
            "[epoch 9][13/66] loss: 1.6468 PSNR_train: 28.0640\n",
            "[epoch 9][14/66] loss: 2.0209 PSNR_train: 28.1268\n",
            "[epoch 9][15/66] loss: 2.0191 PSNR_train: 27.3732\n",
            "[epoch 9][16/66] loss: 3.2428 PSNR_train: 27.6263\n",
            "[epoch 9][17/66] loss: 2.0096 PSNR_train: 27.8118\n",
            "[epoch 9][18/66] loss: 3.4270 PSNR_train: 28.1649\n",
            "[epoch 9][19/66] loss: 2.3068 PSNR_train: 26.8690\n",
            "[epoch 9][20/66] loss: 1.9600 PSNR_train: 27.4546\n",
            "[epoch 9][21/66] loss: 2.4214 PSNR_train: 27.3009\n",
            "[epoch 9][22/66] loss: 3.5300 PSNR_train: 27.5565\n",
            "[epoch 9][23/66] loss: 1.9584 PSNR_train: 27.8606\n",
            "[epoch 9][24/66] loss: 1.6286 PSNR_train: 27.6317\n",
            "[epoch 9][25/66] loss: 1.9439 PSNR_train: 27.5598\n",
            "[epoch 9][26/66] loss: 2.1401 PSNR_train: 27.5273\n",
            "[epoch 9][27/66] loss: 1.9180 PSNR_train: 27.9453\n",
            "[epoch 9][28/66] loss: 2.0699 PSNR_train: 27.3265\n",
            "[epoch 9][29/66] loss: 2.3231 PSNR_train: 27.2995\n",
            "[epoch 9][30/66] loss: 1.6858 PSNR_train: 28.1810\n",
            "[epoch 9][31/66] loss: 1.8574 PSNR_train: 27.7163\n",
            "[epoch 9][32/66] loss: 2.1101 PSNR_train: 27.2612\n",
            "[epoch 9][33/66] loss: 2.0983 PSNR_train: 27.0398\n",
            "[epoch 9][34/66] loss: 1.9738 PSNR_train: 27.5859\n",
            "[epoch 9][35/66] loss: 1.6188 PSNR_train: 27.9745\n",
            "[epoch 9][36/66] loss: 1.6662 PSNR_train: 27.4932\n",
            "[epoch 9][37/66] loss: 1.9877 PSNR_train: 26.6442\n",
            "[epoch 9][38/66] loss: 3.0736 PSNR_train: 26.4014\n",
            "[epoch 9][39/66] loss: 1.8655 PSNR_train: 27.6010\n",
            "[epoch 9][40/66] loss: 3.4776 PSNR_train: 28.3132\n",
            "[epoch 9][41/66] loss: 1.8656 PSNR_train: 27.2532\n",
            "[epoch 9][42/66] loss: 1.9880 PSNR_train: 27.3028\n",
            "[epoch 9][43/66] loss: 2.0691 PSNR_train: 27.3326\n",
            "[epoch 9][44/66] loss: 1.7849 PSNR_train: 27.7845\n",
            "[epoch 9][45/66] loss: 2.3132 PSNR_train: 28.1453\n",
            "[epoch 9][46/66] loss: 2.4525 PSNR_train: 28.4330\n",
            "[epoch 9][47/66] loss: 2.7022 PSNR_train: 27.4090\n",
            "[epoch 9][48/66] loss: 1.5538 PSNR_train: 28.4429\n",
            "[epoch 9][49/66] loss: 1.9729 PSNR_train: 28.0597\n",
            "[epoch 9][50/66] loss: 2.2921 PSNR_train: 27.4068\n",
            "[epoch 9][51/66] loss: 2.0758 PSNR_train: 27.4578\n",
            "[epoch 9][52/66] loss: 2.0067 PSNR_train: 27.4289\n",
            "[epoch 9][53/66] loss: 1.7069 PSNR_train: 27.8020\n",
            "[epoch 9][54/66] loss: 1.9866 PSNR_train: 27.7337\n",
            "[epoch 9][55/66] loss: 1.7043 PSNR_train: 27.9541\n",
            "[epoch 9][56/66] loss: 2.1869 PSNR_train: 27.4871\n",
            "[epoch 9][57/66] loss: 2.2115 PSNR_train: 26.8881\n",
            "[epoch 9][58/66] loss: 1.9594 PSNR_train: 27.5553\n",
            "[epoch 9][59/66] loss: 1.6576 PSNR_train: 27.9139\n",
            "[epoch 9][60/66] loss: 2.1119 PSNR_train: 26.7368\n",
            "[epoch 9][61/66] loss: 2.2391 PSNR_train: 26.7598\n",
            "[epoch 9][62/66] loss: 1.7531 PSNR_train: 28.0736\n",
            "[epoch 9][63/66] loss: 1.7743 PSNR_train: 28.1240\n",
            "[epoch 9][64/66] loss: 2.9620 PSNR_train: 27.5448\n",
            "[epoch 9][65/66] loss: 1.6029 PSNR_train: 27.9325\n",
            "[epoch 9][66/66] loss: 1.6698 PSNR_train: 29.0378\n",
            "\n",
            "[epoch 9] PSNR_val: 25.0307\n",
            "learning rate 0.000100\n",
            "[epoch 10][1/66] loss: 2.2437 PSNR_train: 26.9243\n",
            "[epoch 10][2/66] loss: 1.9352 PSNR_train: 27.4089\n",
            "[epoch 10][3/66] loss: 2.2408 PSNR_train: 27.4123\n",
            "[epoch 10][4/66] loss: 1.9269 PSNR_train: 27.5273\n",
            "[epoch 10][5/66] loss: 2.0134 PSNR_train: 27.6022\n",
            "[epoch 10][6/66] loss: 2.1272 PSNR_train: 27.8598\n",
            "[epoch 10][7/66] loss: 2.3250 PSNR_train: 27.8677\n",
            "[epoch 10][8/66] loss: 1.7558 PSNR_train: 27.1606\n",
            "[epoch 10][9/66] loss: 2.6983 PSNR_train: 27.3768\n",
            "[epoch 10][10/66] loss: 2.0799 PSNR_train: 27.4062\n",
            "[epoch 10][11/66] loss: 1.7750 PSNR_train: 27.6431\n",
            "[epoch 10][12/66] loss: 1.9664 PSNR_train: 28.1600\n",
            "[epoch 10][13/66] loss: 2.7976 PSNR_train: 27.2072\n",
            "[epoch 10][14/66] loss: 1.9156 PSNR_train: 27.8481\n",
            "[epoch 10][15/66] loss: 1.6463 PSNR_train: 27.7864\n",
            "[epoch 10][16/66] loss: 1.9399 PSNR_train: 27.3611\n",
            "[epoch 10][17/66] loss: 2.3382 PSNR_train: 27.4242\n",
            "[epoch 10][18/66] loss: 2.0000 PSNR_train: 27.4615\n",
            "[epoch 10][19/66] loss: 1.8931 PSNR_train: 28.1442\n",
            "[epoch 10][20/66] loss: 2.4451 PSNR_train: 27.2223\n",
            "[epoch 10][21/66] loss: 2.0481 PSNR_train: 27.7673\n",
            "[epoch 10][22/66] loss: 1.6925 PSNR_train: 27.8999\n",
            "[epoch 10][23/66] loss: 2.2292 PSNR_train: 26.8571\n",
            "[epoch 10][24/66] loss: 2.0806 PSNR_train: 27.8459\n",
            "[epoch 10][25/66] loss: 2.2871 PSNR_train: 27.5404\n",
            "[epoch 10][26/66] loss: 2.9088 PSNR_train: 26.8658\n",
            "[epoch 10][27/66] loss: 1.6990 PSNR_train: 27.6796\n",
            "[epoch 10][28/66] loss: 1.7316 PSNR_train: 28.1909\n",
            "[epoch 10][29/66] loss: 2.0015 PSNR_train: 28.1793\n",
            "[epoch 10][30/66] loss: 1.6240 PSNR_train: 28.0863\n",
            "[epoch 10][31/66] loss: 1.9241 PSNR_train: 27.7605\n",
            "[epoch 10][32/66] loss: 2.1466 PSNR_train: 27.6481\n",
            "[epoch 10][33/66] loss: 1.5657 PSNR_train: 28.4006\n",
            "[epoch 10][34/66] loss: 2.1754 PSNR_train: 27.4868\n",
            "[epoch 10][35/66] loss: 2.1414 PSNR_train: 27.7993\n",
            "[epoch 10][36/66] loss: 2.0637 PSNR_train: 27.3234\n",
            "[epoch 10][37/66] loss: 2.4604 PSNR_train: 28.0767\n",
            "[epoch 10][38/66] loss: 1.7519 PSNR_train: 28.1067\n",
            "[epoch 10][39/66] loss: 1.8919 PSNR_train: 27.5017\n",
            "[epoch 10][40/66] loss: 1.8366 PSNR_train: 27.9425\n",
            "[epoch 10][41/66] loss: 1.9039 PSNR_train: 27.8923\n",
            "[epoch 10][42/66] loss: 2.0348 PSNR_train: 26.9500\n",
            "[epoch 10][43/66] loss: 1.6507 PSNR_train: 28.2164\n",
            "[epoch 10][44/66] loss: 2.9707 PSNR_train: 27.1428\n",
            "[epoch 10][45/66] loss: 1.6789 PSNR_train: 28.0098\n",
            "[epoch 10][46/66] loss: 2.3590 PSNR_train: 27.6156\n",
            "[epoch 10][47/66] loss: 1.6248 PSNR_train: 28.1676\n",
            "[epoch 10][48/66] loss: 2.4090 PSNR_train: 28.3794\n",
            "[epoch 10][49/66] loss: 2.0495 PSNR_train: 27.0589\n",
            "[epoch 10][50/66] loss: 1.7118 PSNR_train: 28.4084\n",
            "[epoch 10][51/66] loss: 1.7425 PSNR_train: 28.0154\n",
            "[epoch 10][52/66] loss: 2.2820 PSNR_train: 27.9895\n",
            "[epoch 10][53/66] loss: 1.8032 PSNR_train: 27.5152\n",
            "[epoch 10][54/66] loss: 1.4516 PSNR_train: 27.9094\n",
            "[epoch 10][55/66] loss: 2.4281 PSNR_train: 27.2916\n",
            "[epoch 10][56/66] loss: 1.6055 PSNR_train: 27.6961\n",
            "[epoch 10][57/66] loss: 1.8334 PSNR_train: 27.8250\n",
            "[epoch 10][58/66] loss: 2.6487 PSNR_train: 27.6222\n",
            "[epoch 10][59/66] loss: 1.6568 PSNR_train: 28.3699\n",
            "[epoch 10][60/66] loss: 2.1886 PSNR_train: 28.0385\n",
            "[epoch 10][61/66] loss: 1.7181 PSNR_train: 27.9429\n",
            "[epoch 10][62/66] loss: 2.4773 PSNR_train: 26.9544\n",
            "[epoch 10][63/66] loss: 1.9604 PSNR_train: 27.9106\n",
            "[epoch 10][64/66] loss: 1.5999 PSNR_train: 27.9654\n",
            "[epoch 10][65/66] loss: 1.6704 PSNR_train: 27.9989\n",
            "[epoch 10][66/66] loss: 6.4706 PSNR_train: 27.6260\n",
            "\n",
            "[epoch 10] PSNR_val: 26.4448\n",
            "learning rate 0.000100\n",
            "[epoch 11][1/66] loss: 1.8450 PSNR_train: 27.8333\n",
            "[epoch 11][2/66] loss: 2.1127 PSNR_train: 27.0598\n",
            "[epoch 11][3/66] loss: 2.0436 PSNR_train: 27.2236\n",
            "[epoch 11][4/66] loss: 2.0810 PSNR_train: 27.1444\n",
            "[epoch 11][5/66] loss: 2.3757 PSNR_train: 27.6026\n",
            "[epoch 11][6/66] loss: 2.1503 PSNR_train: 27.0562\n",
            "[epoch 11][7/66] loss: 1.7203 PSNR_train: 27.5599\n",
            "[epoch 11][8/66] loss: 1.9077 PSNR_train: 27.3062\n",
            "[epoch 11][9/66] loss: 2.0223 PSNR_train: 27.8679\n",
            "[epoch 11][10/66] loss: 1.8994 PSNR_train: 27.3096\n",
            "[epoch 11][11/66] loss: 1.6800 PSNR_train: 27.9712\n",
            "[epoch 11][12/66] loss: 2.5221 PSNR_train: 27.6780\n",
            "[epoch 11][13/66] loss: 2.2237 PSNR_train: 27.7594\n",
            "[epoch 11][14/66] loss: 1.5843 PSNR_train: 27.9605\n",
            "[epoch 11][15/66] loss: 1.8144 PSNR_train: 27.3259\n",
            "[epoch 11][16/66] loss: 1.9903 PSNR_train: 27.3155\n",
            "[epoch 11][17/66] loss: 2.0483 PSNR_train: 26.7352\n",
            "[epoch 11][18/66] loss: 1.8969 PSNR_train: 27.1818\n",
            "[epoch 11][19/66] loss: 2.0950 PSNR_train: 27.3103\n",
            "[epoch 11][20/66] loss: 2.2244 PSNR_train: 27.6985\n",
            "[epoch 11][21/66] loss: 2.9365 PSNR_train: 27.1033\n",
            "[epoch 11][22/66] loss: 2.1443 PSNR_train: 27.8870\n",
            "[epoch 11][23/66] loss: 1.8498 PSNR_train: 28.2732\n",
            "[epoch 11][24/66] loss: 1.9464 PSNR_train: 27.5614\n",
            "[epoch 11][25/66] loss: 2.1722 PSNR_train: 27.4962\n",
            "[epoch 11][26/66] loss: 2.2089 PSNR_train: 26.7885\n",
            "[epoch 11][27/66] loss: 1.9181 PSNR_train: 27.5281\n",
            "[epoch 11][28/66] loss: 1.5818 PSNR_train: 28.0031\n",
            "[epoch 11][29/66] loss: 1.6213 PSNR_train: 28.3587\n",
            "[epoch 11][30/66] loss: 2.3734 PSNR_train: 28.3245\n",
            "[epoch 11][31/66] loss: 2.1426 PSNR_train: 26.7648\n",
            "[epoch 11][32/66] loss: 2.2292 PSNR_train: 27.2067\n",
            "[epoch 11][33/66] loss: 2.4735 PSNR_train: 27.8165\n",
            "[epoch 11][34/66] loss: 1.6654 PSNR_train: 27.9760\n",
            "[epoch 11][35/66] loss: 2.3047 PSNR_train: 27.2469\n",
            "[epoch 11][36/66] loss: 1.5830 PSNR_train: 28.0782\n",
            "[epoch 11][37/66] loss: 1.9482 PSNR_train: 27.9979\n",
            "[epoch 11][38/66] loss: 1.6471 PSNR_train: 28.6926\n",
            "[epoch 11][39/66] loss: 2.0620 PSNR_train: 27.6105\n",
            "[epoch 11][40/66] loss: 1.9571 PSNR_train: 27.2918\n",
            "[epoch 11][41/66] loss: 2.4835 PSNR_train: 27.9071\n",
            "[epoch 11][42/66] loss: 1.9440 PSNR_train: 28.2360\n",
            "[epoch 11][43/66] loss: 1.5411 PSNR_train: 28.3937\n",
            "[epoch 11][44/66] loss: 2.0213 PSNR_train: 27.8288\n",
            "[epoch 11][45/66] loss: 1.8189 PSNR_train: 27.3949\n",
            "[epoch 11][46/66] loss: 1.8834 PSNR_train: 27.5399\n",
            "[epoch 11][47/66] loss: 2.0084 PSNR_train: 27.4015\n",
            "[epoch 11][48/66] loss: 1.8766 PSNR_train: 28.4849\n",
            "[epoch 11][49/66] loss: 1.6722 PSNR_train: 28.1979\n",
            "[epoch 11][50/66] loss: 2.1513 PSNR_train: 28.3267\n",
            "[epoch 11][51/66] loss: 2.0943 PSNR_train: 27.8743\n",
            "[epoch 11][52/66] loss: 2.0590 PSNR_train: 28.1176\n",
            "[epoch 11][53/66] loss: 1.9681 PSNR_train: 27.5924\n",
            "[epoch 11][54/66] loss: 1.6403 PSNR_train: 28.3596\n",
            "[epoch 11][55/66] loss: 2.3766 PSNR_train: 28.3352\n",
            "[epoch 11][56/66] loss: 1.5297 PSNR_train: 28.5016\n",
            "[epoch 11][57/66] loss: 1.4771 PSNR_train: 28.9245\n",
            "[epoch 11][58/66] loss: 2.9360 PSNR_train: 27.8860\n",
            "[epoch 11][59/66] loss: 2.1992 PSNR_train: 26.9314\n",
            "[epoch 11][60/66] loss: 1.7028 PSNR_train: 28.0886\n",
            "[epoch 11][61/66] loss: 1.5495 PSNR_train: 28.8692\n",
            "[epoch 11][62/66] loss: 1.9329 PSNR_train: 27.9315\n",
            "[epoch 11][63/66] loss: 1.6953 PSNR_train: 27.8113\n",
            "[epoch 11][64/66] loss: 1.7760 PSNR_train: 27.4582\n",
            "[epoch 11][65/66] loss: 1.6372 PSNR_train: 27.8258\n",
            "[epoch 11][66/66] loss: 2.6496 PSNR_train: 28.1700\n",
            "\n",
            "[epoch 11] PSNR_val: 25.5509\n",
            "learning rate 0.000100\n",
            "[epoch 12][1/66] loss: 1.6777 PSNR_train: 28.2304\n",
            "[epoch 12][2/66] loss: 1.9126 PSNR_train: 27.9301\n",
            "[epoch 12][3/66] loss: 3.1172 PSNR_train: 27.4213\n",
            "[epoch 12][4/66] loss: 1.6505 PSNR_train: 28.3110\n",
            "[epoch 12][5/66] loss: 1.9392 PSNR_train: 27.5413\n",
            "[epoch 12][6/66] loss: 1.7975 PSNR_train: 28.4148\n",
            "[epoch 12][7/66] loss: 2.2089 PSNR_train: 27.3966\n",
            "[epoch 12][8/66] loss: 1.9414 PSNR_train: 27.7981\n",
            "[epoch 12][9/66] loss: 1.7450 PSNR_train: 27.9914\n",
            "[epoch 12][10/66] loss: 2.0343 PSNR_train: 27.5705\n",
            "[epoch 12][11/66] loss: 2.5402 PSNR_train: 27.5254\n",
            "[epoch 12][12/66] loss: 1.8557 PSNR_train: 28.0628\n",
            "[epoch 12][13/66] loss: 2.0192 PSNR_train: 28.3380\n",
            "[epoch 12][14/66] loss: 1.5830 PSNR_train: 28.0643\n",
            "[epoch 12][15/66] loss: 1.5428 PSNR_train: 28.2593\n",
            "[epoch 12][16/66] loss: 1.7729 PSNR_train: 28.2799\n",
            "[epoch 12][17/66] loss: 1.4960 PSNR_train: 28.5024\n",
            "[epoch 12][18/66] loss: 2.6720 PSNR_train: 27.5520\n",
            "[epoch 12][19/66] loss: 1.8059 PSNR_train: 27.9553\n",
            "[epoch 12][20/66] loss: 1.7284 PSNR_train: 27.8333\n",
            "[epoch 12][21/66] loss: 1.6690 PSNR_train: 28.0891\n",
            "[epoch 12][22/66] loss: 1.6389 PSNR_train: 28.2056\n",
            "[epoch 12][23/66] loss: 2.0925 PSNR_train: 28.0948\n",
            "[epoch 12][24/66] loss: 1.7830 PSNR_train: 28.1889\n",
            "[epoch 12][25/66] loss: 1.7741 PSNR_train: 28.1300\n",
            "[epoch 12][26/66] loss: 2.1043 PSNR_train: 27.2286\n",
            "[epoch 12][27/66] loss: 1.9296 PSNR_train: 27.5941\n",
            "[epoch 12][28/66] loss: 1.7701 PSNR_train: 27.8510\n",
            "[epoch 12][29/66] loss: 1.6863 PSNR_train: 28.5637\n",
            "[epoch 12][30/66] loss: 1.6313 PSNR_train: 28.3459\n",
            "[epoch 12][31/66] loss: 2.1735 PSNR_train: 28.6792\n",
            "[epoch 12][32/66] loss: 1.5553 PSNR_train: 28.4248\n",
            "[epoch 12][33/66] loss: 2.6506 PSNR_train: 27.5716\n",
            "[epoch 12][34/66] loss: 2.4308 PSNR_train: 27.7118\n",
            "[epoch 12][35/66] loss: 2.1600 PSNR_train: 27.7580\n",
            "[epoch 12][36/66] loss: 1.9658 PSNR_train: 27.8771\n",
            "[epoch 12][37/66] loss: 1.7244 PSNR_train: 27.8791\n",
            "[epoch 12][38/66] loss: 1.8920 PSNR_train: 28.2728\n",
            "[epoch 12][39/66] loss: 1.8828 PSNR_train: 27.9558\n",
            "[epoch 12][40/66] loss: 1.7517 PSNR_train: 28.0538\n",
            "[epoch 12][41/66] loss: 2.2099 PSNR_train: 28.2899\n",
            "[epoch 12][42/66] loss: 1.6105 PSNR_train: 28.3023\n",
            "[epoch 12][43/66] loss: 1.9404 PSNR_train: 27.0784\n",
            "[epoch 12][44/66] loss: 1.4706 PSNR_train: 28.6102\n",
            "[epoch 12][45/66] loss: 1.7845 PSNR_train: 27.5992\n",
            "[epoch 12][46/66] loss: 1.8473 PSNR_train: 27.4515\n",
            "[epoch 12][47/66] loss: 1.6705 PSNR_train: 27.9277\n",
            "[epoch 12][48/66] loss: 1.7122 PSNR_train: 27.6615\n",
            "[epoch 12][49/66] loss: 1.6715 PSNR_train: 27.8789\n",
            "[epoch 12][50/66] loss: 1.6880 PSNR_train: 28.1448\n",
            "[epoch 12][51/66] loss: 1.6792 PSNR_train: 28.6491\n",
            "[epoch 12][52/66] loss: 1.8136 PSNR_train: 28.1960\n",
            "[epoch 12][53/66] loss: 2.2270 PSNR_train: 27.5167\n",
            "[epoch 12][54/66] loss: 1.6943 PSNR_train: 27.7645\n",
            "[epoch 12][55/66] loss: 1.8390 PSNR_train: 27.4506\n",
            "[epoch 12][56/66] loss: 1.7580 PSNR_train: 27.8388\n",
            "[epoch 12][57/66] loss: 1.8228 PSNR_train: 27.6421\n",
            "[epoch 12][58/66] loss: 1.5924 PSNR_train: 28.3371\n",
            "[epoch 12][59/66] loss: 1.7764 PSNR_train: 28.7058\n",
            "[epoch 12][60/66] loss: 1.6218 PSNR_train: 28.3601\n",
            "[epoch 12][61/66] loss: 1.5958 PSNR_train: 27.9364\n",
            "[epoch 12][62/66] loss: 3.1033 PSNR_train: 28.2512\n",
            "[epoch 12][63/66] loss: 1.8474 PSNR_train: 27.7286\n",
            "[epoch 12][64/66] loss: 2.0720 PSNR_train: 28.1054\n",
            "[epoch 12][65/66] loss: 1.5502 PSNR_train: 28.4628\n",
            "[epoch 12][66/66] loss: 4.8672 PSNR_train: 26.2028\n",
            "\n",
            "[epoch 12] PSNR_val: 26.0642\n",
            "learning rate 0.000100\n",
            "[epoch 13][1/66] loss: 1.5843 PSNR_train: 27.4073\n",
            "[epoch 13][2/66] loss: 1.9304 PSNR_train: 26.7666\n",
            "[epoch 13][3/66] loss: 1.9245 PSNR_train: 27.2777\n",
            "[epoch 13][4/66] loss: 1.6704 PSNR_train: 27.8525\n",
            "[epoch 13][5/66] loss: 1.9467 PSNR_train: 27.7689\n",
            "[epoch 13][6/66] loss: 1.9826 PSNR_train: 27.8230\n",
            "[epoch 13][7/66] loss: 1.6717 PSNR_train: 27.9347\n",
            "[epoch 13][8/66] loss: 1.6348 PSNR_train: 27.8276\n",
            "[epoch 13][9/66] loss: 1.7224 PSNR_train: 27.9607\n",
            "[epoch 13][10/66] loss: 2.2072 PSNR_train: 27.7528\n",
            "[epoch 13][11/66] loss: 2.1211 PSNR_train: 27.1068\n",
            "[epoch 13][12/66] loss: 1.6379 PSNR_train: 28.4104\n",
            "[epoch 13][13/66] loss: 3.1707 PSNR_train: 27.6840\n",
            "[epoch 13][14/66] loss: 1.6279 PSNR_train: 27.4925\n",
            "[epoch 13][15/66] loss: 1.7718 PSNR_train: 26.8886\n",
            "[epoch 13][16/66] loss: 3.0696 PSNR_train: 27.7936\n",
            "[epoch 13][17/66] loss: 2.2476 PSNR_train: 27.1955\n",
            "[epoch 13][18/66] loss: 2.0684 PSNR_train: 27.6500\n",
            "[epoch 13][19/66] loss: 1.8614 PSNR_train: 28.4222\n",
            "[epoch 13][20/66] loss: 2.3376 PSNR_train: 28.1290\n",
            "[epoch 13][21/66] loss: 2.1769 PSNR_train: 27.3469\n",
            "[epoch 13][22/66] loss: 1.9295 PSNR_train: 27.3364\n",
            "[epoch 13][23/66] loss: 2.0085 PSNR_train: 27.6427\n",
            "[epoch 13][24/66] loss: 2.1084 PSNR_train: 27.6640\n",
            "[epoch 13][25/66] loss: 2.3083 PSNR_train: 27.5097\n",
            "[epoch 13][26/66] loss: 2.1240 PSNR_train: 27.7073\n",
            "[epoch 13][27/66] loss: 1.5979 PSNR_train: 28.2576\n",
            "[epoch 13][28/66] loss: 1.8576 PSNR_train: 27.3228\n",
            "[epoch 13][29/66] loss: 1.7040 PSNR_train: 27.6017\n",
            "[epoch 13][30/66] loss: 2.0512 PSNR_train: 28.0772\n",
            "[epoch 13][31/66] loss: 1.7702 PSNR_train: 27.3722\n",
            "[epoch 13][32/66] loss: 1.5443 PSNR_train: 29.0063\n",
            "[epoch 13][33/66] loss: 1.7096 PSNR_train: 27.8850\n",
            "[epoch 13][34/66] loss: 1.6117 PSNR_train: 28.2466\n",
            "[epoch 13][35/66] loss: 1.7790 PSNR_train: 27.5008\n",
            "[epoch 13][36/66] loss: 2.0759 PSNR_train: 28.0085\n",
            "[epoch 13][37/66] loss: 1.8079 PSNR_train: 27.4202\n",
            "[epoch 13][38/66] loss: 2.1756 PSNR_train: 28.5405\n",
            "[epoch 13][39/66] loss: 1.9984 PSNR_train: 27.6611\n",
            "[epoch 13][40/66] loss: 1.6384 PSNR_train: 28.2087\n",
            "[epoch 13][41/66] loss: 1.7441 PSNR_train: 28.0036\n",
            "[epoch 13][42/66] loss: 1.6608 PSNR_train: 27.7498\n",
            "[epoch 13][43/66] loss: 1.5167 PSNR_train: 28.7754\n",
            "[epoch 13][44/66] loss: 1.7216 PSNR_train: 28.4286\n",
            "[epoch 13][45/66] loss: 2.5950 PSNR_train: 28.2305\n",
            "[epoch 13][46/66] loss: 1.6924 PSNR_train: 28.5896\n",
            "[epoch 13][47/66] loss: 1.7669 PSNR_train: 27.7550\n",
            "[epoch 13][48/66] loss: 1.7949 PSNR_train: 27.5390\n",
            "[epoch 13][49/66] loss: 1.6786 PSNR_train: 28.0064\n",
            "[epoch 13][50/66] loss: 1.7532 PSNR_train: 28.4429\n",
            "[epoch 13][51/66] loss: 1.6354 PSNR_train: 28.4445\n",
            "[epoch 13][52/66] loss: 1.7149 PSNR_train: 28.3700\n",
            "[epoch 13][53/66] loss: 1.9765 PSNR_train: 27.4559\n",
            "[epoch 13][54/66] loss: 2.2310 PSNR_train: 27.9919\n",
            "[epoch 13][55/66] loss: 1.6728 PSNR_train: 27.9476\n",
            "[epoch 13][56/66] loss: 1.8065 PSNR_train: 28.4184\n",
            "[epoch 13][57/66] loss: 1.3355 PSNR_train: 28.7931\n",
            "[epoch 13][58/66] loss: 2.9616 PSNR_train: 27.5561\n",
            "[epoch 13][59/66] loss: 1.9301 PSNR_train: 27.9020\n",
            "[epoch 13][60/66] loss: 1.5813 PSNR_train: 28.3377\n",
            "[epoch 13][61/66] loss: 1.5992 PSNR_train: 28.3196\n",
            "[epoch 13][62/66] loss: 1.5468 PSNR_train: 28.8152\n",
            "[epoch 13][63/66] loss: 1.7483 PSNR_train: 28.6057\n",
            "[epoch 13][64/66] loss: 1.7961 PSNR_train: 28.1812\n",
            "[epoch 13][65/66] loss: 1.8585 PSNR_train: 28.0889\n",
            "[epoch 13][66/66] loss: 4.1149 PSNR_train: 26.7363\n",
            "\n",
            "[epoch 13] PSNR_val: 27.0250\n",
            "learning rate 0.000100\n",
            "[epoch 14][1/66] loss: 2.0205 PSNR_train: 27.7906\n",
            "[epoch 14][2/66] loss: 2.4375 PSNR_train: 27.8892\n",
            "[epoch 14][3/66] loss: 1.8459 PSNR_train: 27.8524\n",
            "[epoch 14][4/66] loss: 1.5130 PSNR_train: 29.0545\n",
            "[epoch 14][5/66] loss: 2.0015 PSNR_train: 28.2122\n",
            "[epoch 14][6/66] loss: 3.4288 PSNR_train: 27.1672\n",
            "[epoch 14][7/66] loss: 1.6682 PSNR_train: 27.9179\n",
            "[epoch 14][8/66] loss: 1.8337 PSNR_train: 27.3235\n",
            "[epoch 14][9/66] loss: 1.6275 PSNR_train: 27.7993\n",
            "[epoch 14][10/66] loss: 1.9015 PSNR_train: 27.3633\n",
            "[epoch 14][11/66] loss: 2.2138 PSNR_train: 27.3095\n",
            "[epoch 14][12/66] loss: 1.7514 PSNR_train: 28.4299\n",
            "[epoch 14][13/66] loss: 1.7410 PSNR_train: 28.7550\n",
            "[epoch 14][14/66] loss: 1.7231 PSNR_train: 28.0421\n",
            "[epoch 14][15/66] loss: 1.7413 PSNR_train: 27.9130\n",
            "[epoch 14][16/66] loss: 1.8076 PSNR_train: 27.6875\n",
            "[epoch 14][17/66] loss: 1.5559 PSNR_train: 28.3688\n",
            "[epoch 14][18/66] loss: 1.7362 PSNR_train: 27.8815\n",
            "[epoch 14][19/66] loss: 1.7367 PSNR_train: 27.5095\n",
            "[epoch 14][20/66] loss: 2.0424 PSNR_train: 28.0823\n",
            "[epoch 14][21/66] loss: 1.5210 PSNR_train: 27.8542\n",
            "[epoch 14][22/66] loss: 1.6967 PSNR_train: 27.9204\n",
            "[epoch 14][23/66] loss: 1.9140 PSNR_train: 27.3428\n",
            "[epoch 14][24/66] loss: 2.2028 PSNR_train: 28.3021\n",
            "[epoch 14][25/66] loss: 1.8421 PSNR_train: 27.4437\n",
            "[epoch 14][26/66] loss: 1.6297 PSNR_train: 28.0261\n",
            "[epoch 14][27/66] loss: 1.6423 PSNR_train: 28.4351\n",
            "[epoch 14][28/66] loss: 1.4468 PSNR_train: 29.1848\n",
            "[epoch 14][29/66] loss: 1.6581 PSNR_train: 28.0007\n",
            "[epoch 14][30/66] loss: 1.7871 PSNR_train: 28.8714\n",
            "[epoch 14][31/66] loss: 1.8162 PSNR_train: 28.5023\n",
            "[epoch 14][32/66] loss: 2.0845 PSNR_train: 27.6177\n",
            "[epoch 14][33/66] loss: 2.0980 PSNR_train: 27.6582\n",
            "[epoch 14][34/66] loss: 2.0249 PSNR_train: 27.0602\n",
            "[epoch 14][35/66] loss: 1.8210 PSNR_train: 27.6782\n",
            "[epoch 14][36/66] loss: 1.8618 PSNR_train: 27.3636\n",
            "[epoch 14][37/66] loss: 1.6911 PSNR_train: 28.6213\n",
            "[epoch 14][38/66] loss: 1.5611 PSNR_train: 28.9022\n",
            "[epoch 14][39/66] loss: 1.8106 PSNR_train: 27.5069\n",
            "[epoch 14][40/66] loss: 1.7168 PSNR_train: 27.6708\n",
            "[epoch 14][41/66] loss: 1.9750 PSNR_train: 27.7939\n",
            "[epoch 14][42/66] loss: 1.6702 PSNR_train: 28.3326\n",
            "[epoch 14][43/66] loss: 2.1538 PSNR_train: 28.0365\n",
            "[epoch 14][44/66] loss: 1.6767 PSNR_train: 27.8886\n",
            "[epoch 14][45/66] loss: 1.7745 PSNR_train: 27.5490\n",
            "[epoch 14][46/66] loss: 1.6220 PSNR_train: 28.0256\n",
            "[epoch 14][47/66] loss: 2.2501 PSNR_train: 28.3003\n",
            "[epoch 14][48/66] loss: 2.0963 PSNR_train: 27.4353\n",
            "[epoch 14][49/66] loss: 2.0735 PSNR_train: 28.3943\n",
            "[epoch 14][50/66] loss: 2.2584 PSNR_train: 28.8060\n",
            "[epoch 14][51/66] loss: 1.6524 PSNR_train: 28.0953\n",
            "[epoch 14][52/66] loss: 1.6337 PSNR_train: 28.0580\n",
            "[epoch 14][53/66] loss: 1.6225 PSNR_train: 28.0602\n",
            "[epoch 14][54/66] loss: 1.5746 PSNR_train: 28.2158\n",
            "[epoch 14][55/66] loss: 1.4881 PSNR_train: 28.3543\n",
            "[epoch 14][56/66] loss: 1.6077 PSNR_train: 28.2310\n",
            "[epoch 14][57/66] loss: 1.5781 PSNR_train: 28.3636\n",
            "[epoch 14][58/66] loss: 1.4754 PSNR_train: 28.6681\n",
            "[epoch 14][59/66] loss: 1.5408 PSNR_train: 28.4286\n",
            "[epoch 14][60/66] loss: 1.9490 PSNR_train: 27.5054\n",
            "[epoch 14][61/66] loss: 1.7090 PSNR_train: 28.4640\n",
            "[epoch 14][62/66] loss: 1.7037 PSNR_train: 28.2806\n",
            "[epoch 14][63/66] loss: 1.6077 PSNR_train: 28.2161\n",
            "[epoch 14][64/66] loss: 1.7271 PSNR_train: 28.1596\n",
            "[epoch 14][65/66] loss: 1.9716 PSNR_train: 27.7738\n",
            "[epoch 14][66/66] loss: 3.6993 PSNR_train: 28.9217\n",
            "\n",
            "[epoch 14] PSNR_val: 27.0589\n",
            "learning rate 0.000100\n",
            "[epoch 15][1/66] loss: 1.8381 PSNR_train: 27.9800\n",
            "[epoch 15][2/66] loss: 1.7965 PSNR_train: 28.0658\n",
            "[epoch 15][3/66] loss: 2.1303 PSNR_train: 27.5760\n",
            "[epoch 15][4/66] loss: 1.8974 PSNR_train: 27.8482\n",
            "[epoch 15][5/66] loss: 1.2852 PSNR_train: 29.2543\n",
            "[epoch 15][6/66] loss: 2.1896 PSNR_train: 28.1766\n",
            "[epoch 15][7/66] loss: 1.6194 PSNR_train: 27.9489\n",
            "[epoch 15][8/66] loss: 2.4105 PSNR_train: 27.7468\n",
            "[epoch 15][9/66] loss: 1.7238 PSNR_train: 27.9087\n",
            "[epoch 15][10/66] loss: 1.8483 PSNR_train: 28.0012\n",
            "[epoch 15][11/66] loss: 1.5664 PSNR_train: 28.4676\n",
            "[epoch 15][12/66] loss: 1.5782 PSNR_train: 28.0683\n",
            "[epoch 15][13/66] loss: 1.6845 PSNR_train: 28.3593\n",
            "[epoch 15][14/66] loss: 3.0264 PSNR_train: 28.0463\n",
            "[epoch 15][15/66] loss: 1.7170 PSNR_train: 28.8588\n",
            "[epoch 15][16/66] loss: 1.6954 PSNR_train: 27.9633\n",
            "[epoch 15][17/66] loss: 1.7644 PSNR_train: 28.1819\n",
            "[epoch 15][18/66] loss: 1.7329 PSNR_train: 27.8500\n",
            "[epoch 15][19/66] loss: 1.6608 PSNR_train: 27.8341\n",
            "[epoch 15][20/66] loss: 2.1232 PSNR_train: 27.5190\n",
            "[epoch 15][21/66] loss: 2.6652 PSNR_train: 28.3199\n",
            "[epoch 15][22/66] loss: 1.7273 PSNR_train: 28.2642\n",
            "[epoch 15][23/66] loss: 1.4194 PSNR_train: 28.4756\n",
            "[epoch 15][24/66] loss: 1.8492 PSNR_train: 27.8722\n",
            "[epoch 15][25/66] loss: 1.7578 PSNR_train: 27.9099\n",
            "[epoch 15][26/66] loss: 2.1171 PSNR_train: 27.5002\n",
            "[epoch 15][27/66] loss: 1.5753 PSNR_train: 28.0696\n",
            "[epoch 15][28/66] loss: 1.9689 PSNR_train: 28.1156\n",
            "[epoch 15][29/66] loss: 1.6505 PSNR_train: 28.6779\n",
            "[epoch 15][30/66] loss: 1.6322 PSNR_train: 28.5447\n",
            "[epoch 15][31/66] loss: 1.7216 PSNR_train: 28.1585\n",
            "[epoch 15][32/66] loss: 1.7701 PSNR_train: 28.3266\n",
            "[epoch 15][33/66] loss: 1.6821 PSNR_train: 28.5158\n",
            "[epoch 15][34/66] loss: 1.9949 PSNR_train: 28.2156\n",
            "[epoch 15][35/66] loss: 1.8747 PSNR_train: 27.5942\n",
            "[epoch 15][36/66] loss: 1.9511 PSNR_train: 27.9380\n",
            "[epoch 15][37/66] loss: 1.6723 PSNR_train: 28.4234\n",
            "[epoch 15][38/66] loss: 2.4129 PSNR_train: 27.4738\n",
            "[epoch 15][39/66] loss: 1.3926 PSNR_train: 29.0490\n",
            "[epoch 15][40/66] loss: 1.7422 PSNR_train: 27.3754\n",
            "[epoch 15][41/66] loss: 1.6943 PSNR_train: 27.8186\n",
            "[epoch 15][42/66] loss: 1.6349 PSNR_train: 27.9637\n",
            "[epoch 15][43/66] loss: 2.2208 PSNR_train: 28.8525\n",
            "[epoch 15][44/66] loss: 1.5662 PSNR_train: 27.9485\n",
            "[epoch 15][45/66] loss: 2.9602 PSNR_train: 27.5293\n",
            "[epoch 15][46/66] loss: 1.9211 PSNR_train: 27.7423\n",
            "[epoch 15][47/66] loss: 1.3734 PSNR_train: 29.5401\n",
            "[epoch 15][48/66] loss: 2.0654 PSNR_train: 28.0522\n",
            "[epoch 15][49/66] loss: 1.8116 PSNR_train: 28.4317\n",
            "[epoch 15][50/66] loss: 1.6205 PSNR_train: 28.0419\n",
            "[epoch 15][51/66] loss: 2.0457 PSNR_train: 27.0266\n",
            "[epoch 15][52/66] loss: 1.6817 PSNR_train: 28.0621\n",
            "[epoch 15][53/66] loss: 1.6485 PSNR_train: 28.0762\n",
            "[epoch 15][54/66] loss: 1.8121 PSNR_train: 28.3665\n",
            "[epoch 15][55/66] loss: 1.6500 PSNR_train: 28.4405\n",
            "[epoch 15][56/66] loss: 2.2989 PSNR_train: 27.9913\n",
            "[epoch 15][57/66] loss: 1.6263 PSNR_train: 28.2981\n",
            "[epoch 15][58/66] loss: 2.1013 PSNR_train: 28.9750\n",
            "[epoch 15][59/66] loss: 1.4352 PSNR_train: 28.4300\n",
            "[epoch 15][60/66] loss: 1.8277 PSNR_train: 28.2517\n",
            "[epoch 15][61/66] loss: 1.7953 PSNR_train: 27.6056\n",
            "[epoch 15][62/66] loss: 1.6900 PSNR_train: 27.8423\n",
            "[epoch 15][63/66] loss: 2.1040 PSNR_train: 27.4696\n",
            "[epoch 15][64/66] loss: 1.6748 PSNR_train: 27.9902\n",
            "[epoch 15][65/66] loss: 1.5160 PSNR_train: 28.2613\n",
            "[epoch 15][66/66] loss: 5.4467 PSNR_train: 27.9952\n",
            "\n",
            "[epoch 15] PSNR_val: 27.1322\n",
            "learning rate 0.000100\n",
            "[epoch 16][1/66] loss: 1.4611 PSNR_train: 28.7427\n",
            "[epoch 16][2/66] loss: 2.2940 PSNR_train: 27.7240\n",
            "[epoch 16][3/66] loss: 1.9293 PSNR_train: 27.4885\n",
            "[epoch 16][4/66] loss: 1.6162 PSNR_train: 28.4487\n",
            "[epoch 16][5/66] loss: 1.7250 PSNR_train: 27.7908\n",
            "[epoch 16][6/66] loss: 2.6235 PSNR_train: 28.3293\n",
            "[epoch 16][7/66] loss: 1.7523 PSNR_train: 28.1296\n",
            "[epoch 16][8/66] loss: 1.8464 PSNR_train: 28.2106\n",
            "[epoch 16][9/66] loss: 1.7698 PSNR_train: 27.4085\n",
            "[epoch 16][10/66] loss: 1.6382 PSNR_train: 28.0966\n",
            "[epoch 16][11/66] loss: 1.7447 PSNR_train: 27.2717\n",
            "[epoch 16][12/66] loss: 2.0611 PSNR_train: 27.4951\n",
            "[epoch 16][13/66] loss: 3.0783 PSNR_train: 28.2324\n",
            "[epoch 16][14/66] loss: 1.7436 PSNR_train: 28.0261\n",
            "[epoch 16][15/66] loss: 1.4952 PSNR_train: 28.2411\n",
            "[epoch 16][16/66] loss: 1.7052 PSNR_train: 27.7636\n",
            "[epoch 16][17/66] loss: 3.1406 PSNR_train: 27.5267\n",
            "[epoch 16][18/66] loss: 1.8824 PSNR_train: 27.5463\n",
            "[epoch 16][19/66] loss: 4.1969 PSNR_train: 28.5611\n",
            "[epoch 16][20/66] loss: 1.7126 PSNR_train: 27.9500\n",
            "[epoch 16][21/66] loss: 2.0407 PSNR_train: 27.7490\n",
            "[epoch 16][22/66] loss: 1.6574 PSNR_train: 28.0655\n",
            "[epoch 16][23/66] loss: 1.5876 PSNR_train: 27.9531\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "xdYWGykCqAXi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}